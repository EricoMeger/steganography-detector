%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% How to use writeLaTeX: 
%
% You edit the source code here on the left, and the preview on the
% right shows you the result within a few seconds.
%
% Bookmark this page and share the URL with your co-authors. They can
% edit at the same time!
%
% You can upload figures, bibliographies, custom classes and
% styles using the files menu.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[12pt]{article}

\usepackage{include/template/sbc-template}

\usepackage{graphicx,url}

%\usepackage[brazil]{babel}   
\usepackage[utf8]{inputenc}  

\renewcommand\refname{Referências} % Troca nome da secao de references para referencias

\sloppy

\title{Bibliotecas de Software Livre para Detecção de Esteganografia em Imagens Digitais}

\author{Érico Meger\inst{1}, Eros Henrique Lunardon Andrade\inst{1}, Guilherme Werneck de Oliveira\inst{1}}


\address{Campus Pinhais – Instituto Federal do Paraná (IFPR)
Pinhais - PR - Brasil}

\begin{document}

\maketitle

\begin{abstract}
  This meta-paper describes the style to be used in articles and short papers
  for SBC conferences. For papers in English, you should add just an abstract
  while for the papers in Portuguese, we also ask for an abstract in
  Portuguese (``resumo''). In both cases, abstracts should not have more than
  10 lines and must be in the first page of the paper.
\end{abstract}

\begin{resumo}
  Este meta-artigo descreve o estilo a ser usado na confecção de artigos e
  resumos de artigos para publicação nos anais das conferências organizadas
  pela SBC. É solicitada a escrita de resumo e abstract apenas para os artigos
  escritos em português. Artigos em inglês deverão apresentar apenas abstract.
  Nos dois casos, o autor deve tomar cuidado para que o resumo (e o abstract)
  não ultrapassem 10 linhas cada, sendo que ambos devem estar na primeira
  página do artigo.
\end{resumo}

\section{Introdução}

O movimento do software livre se estabelece como um paradigma essencial para
promover transparência, colaboração e inovação no cenário tecnológico
contemporâneo. Segundo a Free Software Foundation, software livre é definido
pela sua capacidade de respeitar as liberdades e o controle dos usuários sobre
o software: a liberdade de executar o programa para qualquer propósito, de
estudá-lo e modificá-lo (acesso ao código-fonte é pré-requisito), de
redistribuir cópias e de distribuir versões modificadas para a comunidade,
conhecidas como as quatro liberdades essenciais \cite{gnu_freesw}.

Ao assegurar essas liberdades, o software livre não apenas fortalece a
confiança nas soluções digitais, por permitir auditoria e aprendizado mútuo,
mas também fomenta ambientes colaborativos dinâmicos, onde ferramentas podem
ser aprimoradas coletivamente. Essa filosofia de abertura e colaboração se
manifesta também no campo da inteligência artificial, por meio de bibliotecas
como PyTorch, TensorFlow e scikit-learn. Essas ferramentas de código aberto
democratizam o acesso a algoritmos de aprendizado de máquina, permitindo
reprodutibilidade científica, auditoria de modelos e desenvolvimento
colaborativo de soluções inovadoras \cite{pytorch_about, tensorflow_about}.

No contexto da esteganografia, a disponibilidade dessas bibliotecas open source
oferece grandes oportunidades para o avanço da área. A análise de imagens
digitais, por exemplo, pode se beneficiar de recursos de detecção de padrões e
classificação automática fornecidos por essas ferramentas, auxiliando tanto no
desenvolvimento de técnicas esteganográficas mais robustas quanto na criação de
métodos de detecção mais eficazes. Assim, a intersecção entre software livre,
inteligência artificial e esteganografia evidencia como a filosofia do código
aberto não só fortalece a confiança técnica, mas também amplia as
possibilidades de pesquisa e aplicação prática neste campo.

A esteganografia pode ser compreendida como uma técnica utilizada para esconder
informações em meios aparentemente comuns, de forma que um observador externo
não consiga identificar a presença de dados ocultos \cite{Fridrich2010}.

Essa área de estudo, portanto, não se limita apenas ao ato de esconder
informações, mas constitui um campo de estudo mais amplo que abrange técnicas,
algoritmos e aplicações destinadas a garantir a confidencialidade e a discrição
da comunicação. Em contraste com a criptografia, que protege o conteúdo das
mensagens mas não oculta sua existência, a esteganografia busca mascarar o
próprio ato de comunicação \cite{Fridrich2010}. Essa característica a torna uma
área estratégica tanto para aplicações legítimas, como autenticação de
documentos e proteção da privacidade, quanto para usos maliciosos. Tal
dualidade evidencia que a esteganografia deve ser compreendida não apenas sob
uma perspectiva técnica, mas também dentro de um contexto social e político
mais amplo.

Nesse sentido, ao longo da história, e de forma ainda mais acentuada no cenário
contemporâneo, observa-se o fortalecimento de mecanismos de vigilância e
controle sobre a comunicação digital. Na Europa, por exemplo, esse movimento se
materializa tanto em iniciativas de remoção massiva de conteúdos, com mais de
41 milhões de postagens bloqueadas apenas no primeiro semestre de 2025
\cite{poder3602025}, quanto em pressões políticas para enfraquecer a segurança
criptográfica, como a exigência de um backdoor no iCloud, que levou a Apple a
retirar a opção de criptografia de ponta a ponta de seus serviços no Reino
Unido \cite{guardian2025}. Embora tais medidas sejam frequentemente
justificadas em nome da segurança pública, a ausência de transparência sobre os
critérios de censura e o impacto direto na privacidade digital levantam sérias
preocupações. Nesse contexto, a esteganografia age como uma alternativa
tecnológica de resistência, capaz de proporcionar meios de comunicação
discretos e seguros, reforçando sua relevância sociopolítica e justificando o
aprofundamento de seu estudo.

\subsection{Objetivo}

Explorar o uso de bibliotecas de software livre no desenvolvimento de modelos
de inteligência artificial para a detecção de esteganografia em imagens
digitais.

\section{Revisão bibliográfica} \label{sec:firstpage}
Essa seção revisará os principais trabalhos relacionados, destacando
contribuições, métodos e limitações que fundamentam o desenvolvimento desta
pesquisa.

%trabalho 1

O trabalho \textit{"An Ensemble Model using CNNs on Different Domains for
  ALASKA2 Image Steganalysis"} de Chubachi \cite{chubachi2020cnn} surge da
constatação de que muitos detectores de esteganografia baseados em aprendizado
profundo não generalizam bem em cenários reais devido ao uso de conjuntos de
dados simplificados. A competição ALASKA2 ofereceu um ambiente mais realista,
com imagens JPEG coloridas de diferentes origens e processos, estimulando
soluções mais aplicáveis. Nesse contexto, o objetivo do autor foi desenvolver
um modelo de detecção baseado em um ensemble de redes convolucionais que
combinasse informações tanto do domínio espacial (RGB, YUV e Lab) quanto do
domínio da frequência (coeficientes DCT).

A metodologia proposta envolveu CNNs construídas sobre arquiteturas
EfficientNet, com ajustes para lidar com as especificidades de cada domínio. No
caso dos coeficientes DCT, foram aplicadas codificações one-hot, recortes de
valores e convoluções dilatadas para capturar padrões sutis. Para integrar os
modelos, além da simples média de previsões, foi desenvolvido um perceptron
multicamada capaz de combinar os mapas de características. Também se utilizaram
técnicas auxiliares, como pseudo-rotulagem e stacking com LightGBM. Em
experimentos conduzidos com 300 mil imagens, o uso combinado dos modelos trouxe
ganhos consistentes, resultando em uma performance de AUC ponderado próxima de
0,94 e garantindo a terceira colocação na competição.

O estudo apresenta como pontos fortes a inovação de combinar diferentes
domínios e a validação em um cenário competitivo e realista. Contudo, o alto
custo computacional e a limitação de testar apenas algoritmos de esteganografia
já conhecidos restringem sua aplicabilidade prática.

%trabalho 2

O trabalho \textit{ImageNet Pre-trained CNNs for JPEG Steganalysis} de Yousfi
et al. \cite{fridrich2020imagenet} apresenta uma investigação sobre o uso de
redes neurais convolucionais (CNNs) pré-treinadas para a esteganálise de
imagens JPEG. A principal motivação para o estudo surgiu a partir da competição
de esteganálise ALASKA II, onde foi observado que os participantes com melhor
desempenho utilizavam modelos de visão computacional de uso geral, como
EfficientNet e ResNet, em vez de arquiteturas especializadas e treinadas do
zero para a tarefa. Essa nova abordagem, baseada em aprendizagem por
transferência (transfer learning), representava uma mudança de paradigma em
relação a modelos consolidados, como a SRNet, que eram projetados
especificamente para esteganálise. Diante desse cenário, o principal objetivo
dos autores foi investigar e demonstrar formalmente a eficácia e a
superioridade desses modelos pré-treinados no ImageNet para a detecção de
esteganografia em imagens JPEG, comparando seu desempenho com as abordagens
tradicionais.

A metodologia utilizada centrou-se em refinar (fine-tuning) diversas
arquiteturas pré-treinadas, como EfficientNet, MixNet e ResNet, no conjunto de
dados da ALASKA II. Os autores também conduziram experimentos para avaliar o
impacto de decisões arquitetônicas, como a remoção de camadas de pooling ou
stride no início da rede, confirmando que a manutenção da resolução original
nas primeiras camadas é crucial para a performance em esteganálise. O
experimento principal foi conduzido no dataset da ALASKA II, que continha
imagens comprimidas com fatores de qualidade 75, 90 e 95 e com mensagens
ocultas pelos algoritmos J-UNIWARD, J-MiPOD e UERD.

Os pontos fortes dessa abordagem, destacados no artigo, são a acurácia
superior, a maior eficiência de dados e uma velocidade de treinamento ordens de
magnitude mais rápida em comparação com o treinamento de um modelo do zero.
Como limitação, os próprios autores apontam que o estudo foi amplamente focado
no ambiente da ALASKA II e que o ganho de desempenho obtido com o
pré-treinamento tende a diminuir à medida que o volume de dados para
treinamento na tarefa final aumenta.

%trabalho 3

O estudo \textit{Ensemble of CNNs for Steganalysis: An Empirical Study} de Xu
et al. \cite{xu2016ensemble} é motivado pela observação de que, embora as Redes
Neurais Convolucionais (CNNs) estivessem ganhando popularidade em esteganálise,
a maioria das pesquisas se concentrava no design de um único modelo de CNN. No
entanto, no campo mais amplo da visão computacional e do aprendizado de
máquina, as melhores performances são consistentemente alcançadas por meio de
ensembles, ou seja, a combinação de múltiplos modelos. Os autores perceberam
uma lacuna na literatura de esteganálise, que ainda não havia explorado a fundo
estratégias de ensemble mais sofisticadas do que a simples média das previsões.
O principal objetivo do trabalho foi, portanto, conduzir um estudo empírico
para avaliar o desempenho de diferentes estratégias de combinação de CNNs para
a tarefa de esteganálise, buscando ir além da média de modelos e testar o uso
de classificadores de segundo nível treinados sobre as saídas e representações
internas das redes.

A metodologia proposta envolveu, primeiramente, o treinamento de um conjunto de
16 CNNs individuais, que serviram como "aprendizes de base", cada uma treinada
sobre um subconjunto aleatório do dataset de treinamento. A partir disso, os
autores testaram e compararam três abordagens de ensemble: a média simples das
probabilidades de saída, a criação de novos vetores de características a partir
dessas probabilidades para treinar um classificador de segundo nível, e uma
terceira técnica mais inovadora que consistia em extrair as representações de
características das camadas intermediárias de cada CNN, concatená-las e usá-las
para treinar o classificador de segundo nível. O experimento foi realizado no
dataset BOSSbase v1.01 para detectar a esteganografia do algoritmo S-UNIWARD
com uma taxa de inserção de 0.4 bpp.

O trabalho apresenta como pontos fortes a demonstração sistemática de que o uso
de um classificador de segundo nível sobre as saídas das CNNs melhora
consistentemente o desempenho em relação à média de modelos, e, principalmente,
a descoberta de que o uso das representações de características intermediárias
resulta na melhor performance, indicando que os classificadores mais robustos
podem extrair padrões mais discriminativos do que as camadas de classificação
simples das CNNs base. As limitações do estudo, no entanto, incluem a sua
validação em apenas um dataset, contra um único algoritmo esteganográfico e com
uma única taxa de inserção, além do alto custo computacional da abordagem.

%trabalho 4

O artigo \textit{An Intriguing Struggle of CNNs in JPEG Steganalysis and the
  OneHot Solution} de Yousfi e Fridrich \cite{fridrichOnehot} parte da descoberta
de cenários específicos onde as modernas Redes Neurais Convolucionais (CNNs),
como a SRNet, apresentavam um desempenho surpreendentemente inferior ao de
métodos mais antigos baseados em extração de características, como o JPEG Rich
Model (JRM). Essa falha era particularmente evidente na detecção do algoritmo
nsF5 e do J-UNIWARD em certos tipos de imagem JPEG, e a análise revelou que o
sucesso do JRM nesses casos se devia à sua capacidade de computar estatísticas
simples dos coeficientes DCT, como histogramas de coocorrência, algo que as
CNNs convencionais, que operam na imagem descomprimida, não conseguiam
"enxergar".

A metodologia se baseia em duas inovações principais. A primeira é a própria
rede "OneHot CNN", que transforma sua entrada através de uma camada de
"codificação one-hot com corte" (clipped one-hot encoding). Nessa etapa, os
valores absolutos dos coeficientes DCT são transformados em um volume binário
que facilita o aprendizado de ocorrências e coocorrências pelas camadas
convolucionais subsequentes. A segunda inovação é a arquitetura de ramo duplo
"OneHot+SRNet", que mescla a nova rede OneHot com uma CNN convencional (SRNet).
O experimento principal consistiu em testar o desempenho dessas novas
arquiteturas nos cenários problemáticos (nsF5 e J-UNIWARD) em datasets como
BOSSbase e BOWS2.

O trabalho se destaca por identificar com precisão uma falha em modelos estado
da arte e propor uma solução elegante e eficaz, a codificação one-hot, que
permite a uma CNN aprender estatísticas de alta ordem de forma flexível. A
arquitetura de ramo duplo é outro ponto forte, pois oferece uma maneira prática
de criar um detector mais completo e robusto. Uma limitação implícita é que a
rede OneHot é altamente especializada para esses casos de falha, o que
justifica sua fusão com uma rede mais geral como a SRNet.

%trabalho 5

O artigo \textit{Comprehensive survey on image steganalysis using deep
  learning} de De La Croix et al. \cite{LaCroix2024survey} surge como uma
resposta à evolução e complexidade do campo da esteganálise. A principal
motivação dos autores reside na observação de que as abordagens tradicionais,
baseadas em aprendizado de máquina (ML), se mostraram ineficazes contra os
modernos algoritmos de esteganografia. Métodos clássicos como Support Vector
Machines (SVM) e Ensemble Classifiers (EC) dependem de um processo árduo e
manual de extração de características, o que não só consome tempo, mas também
sofre com a "maldição da dimensionalidade", onde o excesso de características
prejudica o desempenho do classificador. A introdução do aprendizado profundo
(deep learning) marcou uma mudança de paradigma, unificando a extração de
características e a classificação em um único processo otimizado e de ponta a
ponta.

A metodologia empregada pelos autores é a de uma revisão sistemática da
literatura, baseada no protocolo PRISMA. Eles selecionaram 24 artigos de ponta,
publicados entre 2014 e 2023, que representam a vanguarda da esteganálise com
deep learning. O artigo estrutura-se de forma didática, iniciando com uma
taxonomia detalhada das técnicas de esteganálise, explorando a transição do
paradigma de ML para o de deep learning, e analisando as arquiteturas de Redes
Neurais Convolucionais (CNNs) propostas, desde as pioneiras até as mais
recentes. A pesquisa documenta a progressão das arquiteturas, começando com
modelos como Qian-Net, passando pelo Xu-Net, chegando a modelos mais
sofisticados como o Ye-Net, e culminando em arquiteturas estado da arte como a
SRNet e a GBRAS-Net.

Um dos pontos fortes mais significativos desta revisão é a identificação dos
principais desafios que ainda persistem no campo da esteganálise com deep
learning: vulnerabilidade a ataques adversariais, qualidade e padronização dos
datasets, ineficiência para lidar com imagens de tamanhos arbitrários,
dificuldade na detecção de baixo payload, problema do cover-source mismatch,
dificuldade na identificação de características globais, e necessidade de um
grande número de amostras de treinamento. Como limitação, a revisão foca
principalmente em imagens no domínio espacial, deixando lacunas para outros
domínios como JPEG.


% Isso daqui vai ser nossa "conclusão" da revisão bibliográfica, já q é basicamente isso q a gente tem de diferente
Em contraste com os trabalhos revisados, a proposta desenvolvida neste trabalho
busca explorar o uso de bibliotecas de software livre para a construção de
modelos de inteligência artificial em esteganálise, democratizando a área ao
garantir reprodutibilidade, baixo custo e acessibilidade.

\section{Metodologia}

\section{Resultados e discussões}

\section{Conclusão}\label{sec:figs}

% \begin{figure}[ht]
% \centering
% \includegraphics[width=.5\textwidth]{fig1.jpg}
% \caption{A typical figure}
% \label{fig:exampleFig1}
% \end{figure}

% \begin{figure}[ht]
% \centering
% \includegraphics[width=.3\textwidth]{fig2.jpg}
% \caption{This figure is an example of a figure caption taking more than one
%   line and justified considering margins mentioned in Section~\ref{sec:figs}.}
% \label{fig:exampleFig2}
% \end{figure}

% \begin{table}[ht]
% \centering
% \caption{Variables to be considered on the evaluation of interaction
%   techniques}
% \label{tab:exTable1}
% \includegraphics[width=.7\textwidth]{table.jpg}
% \end{table}

\bibliographystyle{include/template/sbc}
\bibliography{include/bibliography/bibliography}

\end{document}
